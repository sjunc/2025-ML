1. 머신러닝의 기본적인 내용에 대해 학습

하나씩 살펴보기

기계학습이라고도 한다.

인간이 직접 프로그래밍을 하던 명시적 프로그래밍
에서 벗어나

데이터에 대해 학습하도록 컴퓨터를 프로그래밍
인간의 코딩량의 감소, 유지 보수에 용이, 정확도 측면 우수, 자동으로 변화에 적응 


스펨 메일에 대해 레이블링을 하고 나면 이후 데이터에 대해 자동 처리

훈련 셋(traing set)
훈련 사례(training instance)   학습하는데 사용하는 샘플 -> 데이터

모델(model) 데이터로 만들어낸 규칙 

데이터 마이닝(data mining): 대용량의 데이터를 분석해서 숨겨진 패턴을 발견하는 것

머신 러닝 강점 분야:
많은 수동 조정과 규칙이 필요한 문제
전통적으론 해결할 수 없는 복잡한 문제
유동적인 환경


범주
지도 / 비지도 / 강화 

지도와 비지도의 확실한 차이
지도(정답이 있는 것)
비지도(정답이 없는 학습)
강화학습(데이터가 없이 스스로)

주기에 따른 학습(배치 학습), 계속해서 실시간으로 하는 학습(온라인 학습)

지도: • 알고리즘에 주입하는 훈련 데이터에 레이블(label)이라는 원하는 답이 포함

ex) 스팸 분류
분류(classification) 
특성(feature)
회귀(regression)


비지도
ex) 정답이 없는 분류 = 군집화 clustering

종류
시각화
특성 추출 
차원 축소 


이상치/ 특이치 탐지
연관 규칙 학습

강화 학습
시간이 지나면서 가장 큰 보상을 얻기 위한 최상의 전략을 스스로 학습


주기적으로 모아서 하는 배치 학습 / 실시간으로 학습하는 온라인 학습

나누어서 학습하는 외부 메모리 학습


학습률: 데이터에 얼마나 빠르게 적응할 것인지 
높으면: 빠르게 적응, 예전 데이터 잃음
낮으면: 느리게 적응, 전체적인 방향을 잘 담을 수 있음. 

사례기반 : 주변에 많은 것으로 
모델 기반: 바운더리를 설정에 포함되는 부분을 보는 것

GDP 대비 행복도
기준선(식)을 만들고 새로운 데이터에 대해 적용

데이터를 준비하기
사람을 위해서 그래프 그리기
모델 설정하기
훈련하기
새 데이터로 테스트 해보기. 

다양한 모델에 따라 결과가 바뀌기도 함.
K-nn, 


머신러닝은 데이터가 중요하다. 
도전 과제

대표성 없는 데이터(데이터 잡음)
적은 데이터
과대 적합 일반성이 없어짐. 
과소 적합 정확도가 떨어짐.

규제: 과대적합의 위험을 줄이기 위해 모델에 규제를 적용 

머신러닝 검증 방법
일반적으로 데이터 80을 학습 20으로 검증함. 

전체적인 프로젝트 진행 방법

큰그림 -> 데이터 구하기(의뢰) -> 데이터 탐색(시각화) -> 데이터준비 -> 훈련 -> 모델 조정 ->  솔루션 제시 -> 모니터링 

비지니스 모델이 무엇인가? 중요 

성능 측정 지표

가정 검사 

info() 
간단한 설명 제공
|
문자열 데이터는 어떻게 처리? Null 값이 있는 건 어떻게 처리

value_counts() 얼마나 있는지 파악

describe() 숫자형 데이터에 대해 파악

hist() 모든 데이터셋에 대한 그래핑 생성

train_test_split() 함수 
테스트 셋과 학습 셋을 간단히 나눔. train_test_split(housing, test_size = 0.2, random_state = 42)
								데이터셋명,  테스트할 양,   시드 

계층적 샘플링
회귀가 아닌 분류를 할 때 도움이 됨. 

지리에 대한 데이터 
alpha 값으로 투명도 (밀집도 확인 가능)

corr() 메서드
그 부분이 다른 것과 어떤 상관관계가 있는지 나옴. 

그림 그릴 수 있는 것.

특성을 조합 가능 

자동 데이터
데이터 정제

Null 값이 있을 때
해당 구역을 제거
그 특성 자체를 제거 
중간 값으로 대체 클래스 SinpleImputer(strategy = "median")

숫자로 바꿔주기 (사이가 숫자적 차이가 아닌 경우 문제가 생기)

One hot encodding 0과 1로 교체해주는 것 

방사 기저 함수
고정 포인트에서 멀어질수록 출력값이 지수값에서 멀어짐. 

센프란시스코 중심 지역 대비 비교

훈련세트에서 훈련하고 검증
RMSE와 
K-fold 교차 검증

모델을 미세 튜닝

GridSearchCV 
설정한 범위에서 결과를 돌려보고 결과를 알려줌.

cv_result 최고로 좋은 값

grid는 너무 느림. RandomSearchCV를 쓰기도 함. 

사용자는 웹어플리케이션을 통해 서버와 소통해서 인공지능을 씀


분류(classfication)

A, B, C /  O, X

MNIST 데이터셋 분류 (손글씨)

이진분류기 (Yes or No)
SGDClassifier 모델을 만들고 전체 훈련 세트를 사용해 훈련

오차 행렬
TN FP FN TP
True Negative False Positive
TP TN
5를 예측할 때 5가 맞다고 제대로 예측한 것과 5가 아니라고 제대로 예측한 것 


오차행률을 통해 만드는 값
정밀도											TP	
양성 예측의 정확도								 ______________
											    TP + FP

재현율											TP
분류기가 정확하게 감지한 양성 샘플의 비율(진짜 양성 비율)	  _____________
f1_score() 정밀도와 재현율로 구하는 머신러닝 성능 척도		   TP + FN

												2			    정밀도 X 재현율
								F1 점수   =   ___________________________ = 2X __________________
										  1			1		    정밀도 X 재현율
										________      +  __________
										정밀도            재현율
정밀도/재현율 트레이드 오프
정밀도와 재현율이 반비례일 때. 정밀도가 올라가면 재현율은 내려감. 
여러가지 임계값

적절한 임계값 설정 방법

정밀도와 재현율 시각화
정밀도를 최우선으로 하되 적절하게 선택

ROC 곡선
거짓 양성 비율에 대한 진짜 양성 비율에 대한 곡선

선이 왼쪽 위에 붙을 수록 완벽한 분류

선 밑의 면적 AUC
AUC가 1이고 완전한 랜덤 분류기(점선) 0.5 가 완벽한 분류기 

성능 측정 수단

다중 분류
A B C D
0~9 까지 예측

그래프를 그려 뭐가 어떤 걸로 잘 못 예측 되었는지 오류 분석

SVM(Support Vector Machine)
분류의 선을 그을 때 점선의 범위를 좁게 할지 넓게 할지 

하드 마진 분류: 모든 데이터가 정확히 분류되어야함. 이상치가 있는 경우 불가능 

소프트 마진 분류: 폭이 있어서 넓게 유지하는 분류


C =1 
숫자가 작아질 수록 범위가 넓어짐. 데이터 친화적 
SVM 모델이 과대적합이라면 C를 감소시켜 모델을 규제

SVC 분류
선형 SVM
비선형 SVM
poly, degree,

가우스R BF 커널
gamma 커질 수록 주변을 더 세게 묶음 

SVR 회귀
epsilon 숫자가 작아질수록 폭이 작아짐 
직선, 곡선

FIFA 선수 실습


객관식 15문제 단답형 주관식 3개. 서술형 2개(어떤 기법은 왜 사용하는지?)






































